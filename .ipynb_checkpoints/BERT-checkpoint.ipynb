{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3769bfd8-7988-4a60-a7b1-4f8706685a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49f47c9e-91c0-4ddc-8eb7-4c4460c57d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEmbedding(nn.Module) :\n",
    "    def __init__(self, vocab_size, n_segments, max_len, embed_dim, dropout) :\n",
    "        super().__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.seg_embed = nn.Embedding(n_segments, embed_dim)\n",
    "        self.pos_embed = nn.Embedding(max_len, embed_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.pos_inp = torch.tensor([i for i in range(max_len)],)\n",
    "\n",
    "\n",
    "    def forward(self, sequence, segment) : \n",
    "        embed_val = self.tok_embed(sequence) + self.seg_embed(segment) + self.pos_embed(self.pos_inp)\n",
    "        return embed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e17791db-423b-4fd4-b63c-1e92425421ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module) : \n",
    "    def __init__(self, vocab_size, n_segments, max_len, embed_dim, n_layers, attn_heads, dropout ) :\n",
    "        super().__init__()\n",
    "        self.embedding = BERTEmbedding(vocab_size, n_segments, max_len, embed_dim, dropout)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(embed_dim, attn_heads, embed_dim+4)\n",
    "        self.encoder_block = nn.TransformerEncoder(self.encoder_layer, n_layers)\n",
    "\n",
    "    def forward(self, sequence, segment) : \n",
    "        out = self.embedding(sequence, segment)\n",
    "        out = self.encoder_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44b4fb46-a53c-40c0-9843-2756e8ba33b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "VOCAB_SIZE = 30000\n",
    "N_SEGMENTS = 3\n",
    "MAX_LEN = 512\n",
    "EMBED_DIM = 768\n",
    "N_LAYERS = 12\n",
    "ATTN_HEADS = 12\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76576d48-c9cd-4693-a1dd-1f491f65408a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_seq = torch.randint(high=VOCAB_SIZE, size=[MAX_LEN,])\n",
    "sample_seg = torch.randint(high=N_SEGMENTS, size=[MAX_LEN,])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfbcd47-cd6f-4262-8043-dcb871ea813c",
   "metadata": {},
   "source": [
    "# Embedding BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b493bad-335e-4e92-acee-00579898cc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding = BERTEmbedding(VOCAB_SIZE, N_SEGMENTS, MAX_LEN, EMBED_DIM, DROPOUT)\n",
    "\n",
    "embedding_tensor = embedding(sample_seq,sample_seg)\n",
    "print(embedding_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a7996f9-2141-4b93-89eb-14a46c653d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4407,  0.4583,  1.0858,  ..., -0.4173,  1.9546,  0.2517],\n",
       "        [-1.4944,  1.6902,  2.2356,  ...,  0.8020,  3.8421,  1.3661],\n",
       "        [ 1.5868, -1.2223,  2.7905,  ..., -1.4159, -1.8224, -2.4992],\n",
       "        ...,\n",
       "        [-0.2949,  1.0737,  0.1272,  ..., -0.2352,  0.1508,  0.1010],\n",
       "        [-2.1031,  0.1447, -0.3413,  ...,  1.1199, -0.9428, -2.3064],\n",
       "        [-0.0131,  2.3977,  2.0010,  ...,  1.4253,  0.2366, -2.0512]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b423166-22d5-48ce-b8a8-584464ef8907",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41662662-eb1d-4aae-932f-aa576dff0438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4997, -0.8414, -0.9764,  ...,  0.0699,  2.2798, -0.9598],\n",
      "        [-0.9944, -0.9993, -1.7293,  ..., -0.1628,  1.7765, -0.7004],\n",
      "        [-0.7878, -1.0090, -1.7070,  ..., -0.4104,  1.3155, -0.3411],\n",
      "        ...,\n",
      "        [-0.7560, -1.4658, -1.5455,  ..., -0.1756,  1.7452, -0.8167],\n",
      "        [-0.5068, -1.0970, -1.4658,  ...,  0.0860,  2.2402, -0.6997],\n",
      "        [-0.3310, -0.4516, -1.5201,  ..., -0.1194,  1.7818, -0.8136]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bert = BERT(VOCAB_SIZE, N_SEGMENTS, MAX_LEN, EMBED_DIM, N_LAYERS, ATTN_HEADS, DROPOUT)\n",
    "out = bert(sample_seq, sample_seg)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
